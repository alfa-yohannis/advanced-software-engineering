\chapter{Observabilitas Sistem Terdistribusi}

\section{Tujuan Pembelajaran}

Setelah mengikuti sesi ini, peserta diharapkan mampu:
\begin{itemize}
  \item Memahami observabilitas sebagai pendekatan untuk mengenali dan menalar perilaku sistem berdasarkan data runtime, tanpa bergantung pada struktur internal atau kode sumber sistem.
  \item Mengidentifikasi dan menafsirkan metrik, log, dan trace sebagai representasi perilaku sistem terdistribusi yang melibatkan broker, capturer, transformer, dan web server.
  \item Mengaitkan visualisasi observabilitas pada Prometheus dan Grafana dengan kondisi runtime, beban sistem, serta pengalaman pengguna.
\end{itemize}


\section{Konsep Dasar Observabilitas}

\subsection{Observabilitas vs Monitoring}

Monitoring dan observabilitas sering digunakan secara bergantian, namun keduanya merepresentasikan pendekatan yang berbeda dalam memahami perilaku sistem. Monitoring berfokus pada pengawasan kondisi yang telah diketahui sebelumnya, biasanya melalui sekumpulan metrik atau ambang batas yang telah ditentukan. Pendekatan ini menjawab pertanyaan apakah sistem berada dalam kondisi normal atau tidak.

Observabilitas, di sisi lain, berfokus pada kemampuan untuk menalar kondisi internal sistem berdasarkan sinyal eksternal yang dihasilkan selama sistem berjalan. Tujuannya bukan hanya mendeteksi bahwa terjadi masalah, tetapi juga memahami mengapa dan bagaimana masalah tersebut muncul, termasuk dalam situasi yang sebelumnya tidak diprediksi.

Dalam konteks sistem terdistribusi yang terdiri dari broker, capturer, transformer, dan web server, monitoring umumnya menampilkan indikator terpisah pada setiap komponen, seperti penggunaan sumber daya atau status layanan. Pendekatan ini berguna untuk mendeteksi gangguan lokal, namun sering kali tidak cukup untuk menjelaskan perilaku sistem secara menyeluruh ketika terjadi keterlambatan, penumpukan data, atau kegagalan parsial.

Observabilitas memungkinkan pengamatan perilaku lintas komponen dengan mengaitkan metrik, log, dan trace sebagai satu kesatuan. Melalui korelasi data runtime yang dikumpulkan oleh Prometheus dan divisualisasikan melalui Grafana, peserta dapat menelusuri aliran peristiwa dari satu komponen ke komponen lain, serta memahami dampaknya terhadap respons sistem secara keseluruhan.

Dengan demikian, monitoring dapat dipandang sebagai alat untuk menjawab pertanyaan \emph{``apa yang salah''}, sedangkan observabilitas berperan untuk menjawab \emph{``mengapa hal tersebut terjadi''}. Pendekatan observabilitas menjadi penting dalam sistem modern yang bersifat dinamis, terdistribusi, dan sulit dipahami hanya melalui inspeksi statis atau asumsi desain awal.

\subsection{Metrik, Log, dan Trace}

Metrik, log, dan trace merupakan tiga jenis sinyal utama dalam observabilitas yang merepresentasikan perilaku sistem dari sudut pandang yang berbeda. Ketiganya saling melengkapi dan digunakan bersama untuk membangun pemahaman yang utuh terhadap dinamika sistem saat berjalan.

Metrik menyajikan pengukuran numerik teragregasi yang menggambarkan kondisi sistem dalam rentang waktu tertentu. Contoh metrik meliputi laju pemrosesan, latensi, tingkat kesalahan, dan penggunaan sumber daya. Dalam sistem yang terdiri dari broker, capturer, transformer, dan web server, metrik memungkinkan pengamatan tren seperti peningkatan beban, antrian yang menumpuk, atau penurunan throughput tanpa harus melihat peristiwa individual.

Log merekam peristiwa diskret yang terjadi selama eksekusi sistem, biasanya dalam bentuk pesan berurutan yang merefleksikan aktivitas internal komponen. Log memberikan konteks yang lebih kaya dibandingkan metrik, seperti urutan kejadian, kondisi tertentu, atau keputusan yang diambil oleh sistem. Pada sistem terdistribusi, log membantu menjelaskan apa yang sedang dilakukan oleh masing-masing komponen pada saat tertentu, terutama ketika terjadi kegagalan atau perilaku tidak normal.

Trace merepresentasikan alur eksekusi suatu permintaan atau data saat melewati beberapa komponen sistem. Melalui trace, satu peristiwa dapat ditelusuri dari awal hingga akhir, misalnya dari capturer ke broker, diteruskan ke transformer, hingga akhirnya disajikan oleh web server. Trace memberikan gambaran hubungan sebab-akibat antar komponen serta memungkinkan identifikasi titik keterlambatan atau bottleneck dalam alur sistem.

Dalam praktik observabilitas, ketiga sinyal ini tidak digunakan secara terpisah. Metrik sering digunakan untuk mendeteksi adanya anomali, log digunakan untuk memberikan konteks terhadap anomali tersebut, dan trace digunakan untuk menelusuri jalur eksekusi yang menyebabkan kondisi tersebut muncul. Kombinasi ini memungkinkan pemahaman perilaku sistem secara menyeluruh, bahkan ketika masalah yang terjadi tidak pernah didefinisikan sebelumnya.

Dengan memanfaatkan metrik, log, dan trace secara bersamaan, observabilitas memungkinkan peserta untuk berpindah dari pengamatan permukaan menuju pemahaman mendalam terhadap dinamika runtime sistem terdistribusi.


\subsection{Observabilitas sebagai Pendekatan Bottom-Up}

Pendekatan bottom-up dalam observabilitas menekankan pemahaman sistem yang dimulai dari perilaku nyata yang muncul selama eksekusi, bukan dari asumsi desain atau spesifikasi awal. Dalam pendekatan ini, sistem dipahami melalui sinyal runtime yang dihasilkannya, seperti metrik, log, dan trace, yang merefleksikan interaksi aktual antar komponen.

Berbeda dengan pendekatan top-down yang berangkat dari arsitektur, diagram, atau dokumentasi desain, pendekatan bottom-up mengajak peserta untuk terlebih dahulu mengamati apa yang benar-benar terjadi ketika sistem dijalankan. Hal ini menjadi penting terutama pada sistem terdistribusi yang kompleks, di mana perilaku aktual sering kali menyimpang dari ekspektasi desain akibat beban, kegagalan parsial, atau interaksi non-linear antar komponen.

Dalam sistem yang melibatkan broker, capturer, transformer, dan web server, pendekatan bottom-up memungkinkan pengamatan aliran data dan peristiwa tanpa harus memahami implementasi internal masing-masing komponen. Peserta dapat mulai dengan mengamati metrik seperti laju data masuk, latensi pemrosesan, atau tingkat kesalahan, kemudian menelusuri log dan trace untuk memahami hubungan sebab-akibat di balik perubahan yang teramati.

Pendekatan ini juga mendorong eksplorasi sistem secara iteratif. Pengamatan awal terhadap dashboard atau grafik metrik dapat memunculkan pertanyaan baru, yang selanjutnya dijawab dengan memperkaya konteks melalui log dan trace. Proses ini membentuk siklus observasi dan penalaran yang berulang, di mana pemahaman sistem berkembang seiring dengan meningkatnya kedalaman pengamatan.

Dengan menempatkan data runtime sebagai sumber utama pengetahuan, observabilitas sebagai pendekatan bottom-up membantu membangun intuisi tentang perilaku sistem yang bersifat dinamis dan kontekstual. Pendekatan ini sangat relevan untuk sistem modern yang terus berevolusi, berskala besar, dan tidak dapat sepenuhnya dipahami hanya melalui analisis statis atau dokumentasi desain.




\section{Arsitektur Sistem Studi Kasus}


\begin{figure}[htbp]
\centering
\scalebox{0.9}{
\begin{tikzpicture}[
  font=\small\bfseries,
  node distance=9mm and 12mm,
  box/.style={
    draw,
    rounded corners=2mm,
    align=center,
    minimum width=32mm,
    minimum height=9mm,
    fill=blue!10
  },
  brokerbox/.style={box,fill=orange!15},
  webbox/.style={box,fill=green!12},
  browserbox/.style={box,fill=gray!12},
  extbox/.style={box,fill=purple!10},
  arrow/.style={-Latex,thick},
  dottedarrow/.style={-Latex,thick,dotted}
]

% Core nodes (note: Prometheus service embedded in each node)
\node[box ] (transformer) {Transformer\\(Node B)\\{\scriptsize Prometheus service}};
\node[box,left=of transformer, xshift=-10mm] (capturer) {Capturer\\(Node A)\\{\scriptsize Prometheus service}};
\node[brokerbox, below=of capturer, yshift=-5mm] (broker) {Broker\\(XSUB / XPUB)\\{\scriptsize Prometheus service}};

\node[browserbox,below=of broker] (browser) {Browser};
\node[webbox,right=of browser, xshift=10mm](web) {Web Server\\(Node C)\\{\scriptsize Prometheus service}};

% External observability nodes
\node[extbox,right=of web] (grafana) {Grafana};
\node[extbox,above=of grafana, yshift=10mm] (prom) {Prometheus};

% Data flow arrows
\draw[arrow] (capturer) -- node[above, xshift=-8mm]{PUB \texttt{raw}} (broker);
\draw[arrow] (broker) -- node[above, yshift=-5mm, xshift=8mm]{SUB \texttt{raw}} (transformer);
\draw[arrow] (transformer.south) |- node[below]{PUB \texttt{processed}} (broker.east);
\draw[arrow] (broker) -- node[right,xshift=3mm]{SUB \texttt{processed}} (web.north);
\draw[arrow] (web.west) -- node[above]{HTTP MJPEG} (browser.east);

% Observability (scraping + visualization)
\draw[dottedarrow] (capturer.south) -- (prom);
\draw[dottedarrow] (broker) -- (prom);
\draw[dottedarrow] (transformer.east) -- (prom);
\draw[dottedarrow] (web.east) -- (prom);
\draw[arrow] (prom) -- (grafana);

\end{tikzpicture}
}
\caption{Arsitektur aliran data menggunakan komunikasi publish--subscribe berbasis broker, dengan layanan Prometheus tertanam pada setiap node serta Prometheus dan Grafana sebagai komponen observabilitas eksternal}
\label{fig:broker-pubsub-observability}
\end{figure}

Pada Gambar~\ref{fig:broker-pubsub-observability} ditunjukkan arsitektur sistem studi kasus yang digunakan untuk mengeksplorasi perilaku sistem terdistribusi berbasis komunikasi \emph{publish--subscribe}. Arsitektur ini terdiri dari beberapa node utama yang berinteraksi melalui sebuah \emph{message broker}, serta dilengkapi dengan mekanisme observabilitas yang terintegrasi.

Node \textbf{Capturer (Node A)} berperan sebagai sumber data awal. Node ini menghasilkan data mentah (\emph{raw data}) dan mempublikasikannya ke broker menggunakan mekanisme \emph{publish}. Dengan pendekatan ini, produsen data tidak berkomunikasi langsung dengan konsumen, melainkan melalui perantara.

Node \textbf{Broker} berfungsi sebagai pusat pertukaran data dengan pola komunikasi \emph{XSUB/XPUB}. Broker menerima data mentah dari capturer dan mendistribusikannya kepada node yang melakukan \emph{subscribe}. Pola ini memungkinkan pemisahan yang jelas antara pengirim dan penerima data, serta mendukung skalabilitas sistem.

Node \textbf{Transformer (Node B)} melakukan \emph{subscribe} terhadap data mentah dari broker untuk kemudian memprosesnya. Data hasil pemrosesan (\emph{processed data}) dipublikasikan kembali ke broker, sehingga dapat digunakan oleh komponen lain tanpa ketergantungan langsung.

Node \textbf{Web Server (Node C)} melakukan \emph{subscribe} terhadap data hasil pemrosesan dari broker dan menyajikannya kepada pengguna. Penyajian data dilakukan melalui antarmuka web menggunakan protokol HTTP dalam bentuk aliran MJPEG.

Interaksi pengguna direpresentasikan oleh \textbf{Browser}, yang mengakses web server untuk melihat hasil akhir pemrosesan. Dari sudut pandang pengguna, sistem tampak sebagai layanan web, meskipun terdiri dari beberapa komponen terdistribusi di belakang layar.

Setiap node aplikasi dilengkapi dengan \textbf{layanan Prometheus yang tertanam} untuk mengekspor metrik runtime. Metrik-metrik ini mencerminkan perilaku aktual sistem selama eksekusi. Prometheus eksternal bertugas mengumpulkan metrik dari seluruh node melalui mekanisme \emph{scraping}.

Data observabilitas yang telah dikumpulkan selanjutnya divisualisasikan melalui \textbf{Grafana}. Dashboard Grafana memungkinkan pemantauan dan analisis perilaku sistem secara menyeluruh, serta mendukung pendekatan observabilitas berbasis pengamatan langsung terhadap data runtime.

Arsitektur ini dirancang untuk mendukung pendekatan observabilitas \emph{bottom-up}, di mana pemahaman sistem dibangun dari perilaku nyata yang teramati selama sistem berjalan, sebelum dilakukan analisis struktur atau optimasi desain.


\section{Prometheus}

Prometheus merupakan sistem pemantauan dan pengumpulan metrik yang dirancang untuk sistem terdistribusi dan dinamis. Dalam studi kasus ini, Prometheus digunakan sebagai komponen observabilitas terpusat yang mengumpulkan metrik runtime dari setiap node aplikasi, yaitu Capturer, Broker, Transformer, dan Web Server.

Prometheus menerapkan model \emph{pull-based}, di mana server Prometheus secara periodik melakukan pengambilan (\emph{scraping}) metrik dari endpoint yang diekspos oleh masing-masing node. Setiap node aplikasi menjalankan layanan Prometheus tertanam yang mengekspor metrik runtime tanpa mengganggu alur pemrosesan data utama.

Metrik yang dikumpulkan disimpan dalam bentuk \emph{time-series data}, sehingga memungkinkan analisis perilaku sistem sepanjang waktu, termasuk pengamatan tren, lonjakan beban, latensi, serta indikasi kegagalan parsial. Dalam arsitektur ini, Prometheus tidak terlibat langsung dalam alur data aplikasi, melainkan berfungsi murni sebagai mekanisme observasi.

Pada demo ini, Prometheus tidak diinstal secara manual pada sistem operasi host. Prometheus dijalankan sebagai \emph{container} menggunakan \emph{Docker image} resmi yang di-\emph{pull} dari repositori. Pendekatan ini memberikan lingkungan runtime yang konsisten, mudah direproduksi, dan terisolasi dari node aplikasi.

Dengan menjalankan Prometheus sebagai container, konfigurasi scraping dan penyimpanan metrik dapat dikelola secara terpisah dari kode aplikasi. Selain itu, Prometheus dapat dengan mudah dijalankan, dihentikan, atau dikonfigurasi ulang tanpa memengaruhi proses utama sistem studi kasus.

Untuk mendukung ekspor metrik dari aplikasi berbasis Python, digunakan library \texttt{prometheus-client}. Library ini memungkinkan setiap node menyediakan endpoint metrik yang dapat diakses oleh Prometheus eksternal.

\begin{lstlisting}[language=bash]
pip install prometheus-client
\end{lstlisting}

Dengan pendekatan ini, setiap node aplikasi mengekspor sinyal runtime secara mandiri, sementara Prometheus berperan sebagai pengumpul data terpusat yang berjalan sebagai layanan terpisah. Pemisahan peran ini mendukung observabilitas berbasis data runtime dan memungkinkan analisis perilaku sistem secara \emph{bottom-up} sebelum dilakukan penalaran terhadap struktur atau desain sistem.



\section{Grafana}

Grafana merupakan platform visualisasi data yang digunakan untuk menampilkan dan menganalisis metrik yang dikumpulkan oleh Prometheus. Dalam studi kasus ini, Grafana berperan sebagai lapisan presentasi yang memungkinkan pengamatan perilaku sistem secara intuitif melalui \emph{dashboard}.

Grafana tidak mengumpulkan data secara langsung dari node aplikasi. Grafana berfungsi sebagai klien yang melakukan kueri ke Prometheus untuk mengambil data metrik yang telah tersimpan dalam bentuk \emph{time-series}. Pemisahan peran ini memastikan bahwa visualisasi tidak memengaruhi mekanisme pengumpulan maupun pemrosesan data utama sistem.

Pada demo ini, Grafana tidak dipasang secara manual di sistem operasi host. Sebaliknya, Grafana dijalankan sebagai \emph{container} dengan memanfaatkan \emph{Docker image} resmi yang di-\emph{pull} dari repositori. Pendekatan ini memberikan lingkungan runtime yang konsisten, dapat direproduksi, dan mudah dikonfigurasi ulang, terutama dalam konteks eksperimen dan pembelajaran.

Dengan menjalankan Grafana sebagai container, proses penyebaran dan penghentian layanan visualisasi dapat dilakukan tanpa memengaruhi node aplikasi maupun server Prometheus. Selain itu, konfigurasi Grafana, seperti koneksi ke Prometheus dan definisi dashboard, dapat dikelola secara terpisah dari kode aplikasi.

Melalui dashboard Grafana, metrik dari berbagai node seperti Capturer, Broker, Transformer, dan Web Server dapat ditampilkan secara bersamaan. Visualisasi ini memungkinkan perbandingan perilaku antar node, identifikasi pola beban, serta pengamatan perubahan kondisi sistem dari waktu ke waktu.

Dalam konteks pembelajaran, penggunaan Grafana sebagai container juga memperkuat pemahaman bahwa komponen observabilitas dapat diperlakukan sebagai layanan terpisah. Peserta dapat fokus pada interpretasi perilaku sistem melalui dashboard tanpa harus berurusan dengan kompleksitas instalasi perangkat lunak secara manual.

Dengan demikian, Grafana berfungsi sebagai lapisan visualisasi observabilitas yang fleksibel, terisolasi, dan mudah direproduksi, sejalan dengan tujuan demo untuk menekankan observabilitas berbasis data runtime.


\section{OpenTelemetry}


\section{Eksperimen Observabilitas}
\begin{itemize}
  \item Main interface:
    \begin{itemize}
      \item \url{http://localhost:8000/}
      \item \url{http://localhost:8000/stream.mjpg}
    \end{itemize}

  \item Metrics endpoints:
    \begin{itemize}
      \item Capturer: \url{http://localhost:9101/metrics}
      \item Broker: \url{http://localhost:9102/metrics}
      \item Transformer: \url{http://localhost:9103/metrics}
      \item Web server: \url{http://localhost:9104/metrics}
    \end{itemize}

	\item Monitoring:
	\begin{itemize}
		\item Prometheus: \url{http://localhost:9090}
		\item Grafana: \url{http://grafana:3000}
	\end{itemize}

\end{itemize}



\begin{table}[htbp]
\centering
\small
\caption{Summary and comparison of pipeline components}
\label{tab:pipeline-comparison}
\begin{tabular}{|
p{0.10\linewidth}|
p{0.18\linewidth}|
p{0.12\linewidth}|
p{0.12\linewidth}|
p{0.10\linewidth}|
p{0.12\linewidth}|
}
\hline
\textbf{Component} &
\textbf{Primary Role} &
\textbf{Frames (in $\rightarrow$ out)} &
\textbf{Avg Payload Size} &
\textbf{CPU Usage} &
\textbf{RSS Memory} \\
\hline
Capturer &
Video ingest and JPEG encoding &
-- $\rightarrow$ 8\,473 &
$\sim$102 KB &
$\sim$54\% &
$\sim$128 MB \\
\hline
Broker &
XSUB/XPUB message forwarding &
17\,030 $\rightarrow$ 17\,030 (ZMQ frames) &
$\sim$100 KB (data frames) &
$\sim$2\% &
$\sim$32 MB \\
\hline
Transformer &
JPEG decode, grayscale transform, re-encode &
8\,641 $\rightarrow$ 8\,641 &
Input $\sim$102 KB, Output $\sim$99 KB &
$\sim$21\% &
$\sim$45--52 MB \\
\hline
Web Server &
ZMQ receive and HTTP/MJPEG delivery &
8\,819 $\rightarrow$ -- &
$\sim$98.5 KB &
$\sim$0\% (at scrape) &
$\sim$193 MB \\
\hline
\end{tabular}
\end{table}


\begin{table}[htbp]
\centering
\caption{Performance Comparison of Web Server Under Different Numbers of MJPEG Clients}
\label{tab:webserver_clients}
\begin{tabular}{lrrr}
\hline
\textbf{Metric} & \textbf{1 Browser} & \textbf{6 Browsers} & \textbf{Change} \\
\hline
Active MJPEG clients            & 1       & 6       & $\times 6$ \\
Frames received                 & 7{,}070 & 7{,}517 & +6.3\% \\
Bytes received (MB)             & 697     & 741     & +6.3\% \\
Average JPEG size (KB)          & 98.6    & 98.6    & 0\% \\
\hline
Mean end-to-end latency (ms)    & 30.1    & 30.2    & $\approx 0$ \\
95--100\% latency bound (ms)    & $\le$100 & $\le$100 & unchanged \\
\hline
CPU utilisation (\%)            & 1       & 4       & +3 pp \\
Resident memory (MB)            & 133     & 157     & +24 \\
Open file descriptors           & 18      & 23      & +5 \\
\hline
\end{tabular}
\end{table}

\section{Sudut Pandang Mahasiswa Non-IT}

\section{Sudut Pandang Mahasiswa IT}



\section{Diskusi dan Refleksi}


\section{Ringkasan}




